{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91512255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T21:51:54.964409Z",
     "iopub.status.busy": "2024-05-15T21:51:54.963558Z",
     "iopub.status.idle": "2024-05-15T21:51:54.968458Z",
     "shell.execute_reply": "2024-05-15T21:51:54.967547Z"
    },
    "papermill": {
     "duration": 0.016318,
     "end_time": "2024-05-15T21:51:54.970432",
     "exception": false,
     "start_time": "2024-05-15T21:51:54.954114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# credits: https://www.kaggle.com/code/thedrcat/aimo-mixtral-baseline\n",
    "# credits: https://www.kaggle.com/code/aatiffraz/prompt-prediction-w-mixtral-mistral7b-gemma-llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e724712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T21:51:54.985474Z",
     "iopub.status.busy": "2024-05-15T21:51:54.985198Z",
     "iopub.status.idle": "2024-05-15T21:52:33.322809Z",
     "shell.execute_reply": "2024-05-15T21:52:33.321389Z"
    },
    "papermill": {
     "duration": 38.348045,
     "end_time": "2024-05-15T21:52:33.325527",
     "exception": false,
     "start_time": "2024-05-15T21:51:54.977482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e31dd5df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T21:52:33.342330Z",
     "iopub.status.busy": "2024-05-15T21:52:33.341925Z",
     "iopub.status.idle": "2024-05-15T21:52:33.347180Z",
     "shell.execute_reply": "2024-05-15T21:52:33.346172Z"
    },
    "papermill": {
     "duration": 0.016207,
     "end_time": "2024-05-15T21:52:33.349398",
     "exception": false,
     "start_time": "2024-05-15T21:52:33.333191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PRIVATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9c9956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T21:52:33.365425Z",
     "iopub.status.busy": "2024-05-15T21:52:33.365075Z",
     "iopub.status.idle": "2024-05-15T21:52:40.860086Z",
     "shell.execute_reply": "2024-05-15T21:52:40.859276Z"
    },
    "papermill": {
     "duration": 7.505882,
     "end_time": "2024-05-15T21:52:40.862621",
     "exception": false,
     "start_time": "2024-05-15T21:52:33.356739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fdae49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T21:52:40.877978Z",
     "iopub.status.busy": "2024-05-15T21:52:40.877489Z",
     "iopub.status.idle": "2024-05-15T21:52:40.904226Z",
     "shell.execute_reply": "2024-05-15T21:52:40.903347Z"
    },
    "papermill": {
     "duration": 0.037033,
     "end_time": "2024-05-15T21:52:40.906600",
     "exception": false,
     "start_time": "2024-05-15T21:52:40.869567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation environment\n",
    "import aimo\n",
    "\n",
    "PRIVATE = True\n",
    "\n",
    "if PRIVATE:\n",
    "    env = aimo.make_env()\n",
    "else:\n",
    "    df_train = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\n",
    "    class Env:\n",
    "        def __init__(self, df_train):\n",
    "            self.df_train = df_train\n",
    "            self.df_train.set_index('id', inplace=True)\n",
    "            self.df_results = df_train.copy()\n",
    "        def predict(self, x):\n",
    "            self.df_results.loc[x.name, 'answer'] = x['answer']\n",
    "        def iter_test(self):\n",
    "            for i in range(df_train.shape[0]):\n",
    "                yield self.df_train.iloc[i], self.df_results.iloc[i]\n",
    "    env = Env(df_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04ccd9ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T21:52:40.922656Z",
     "iopub.status.busy": "2024-05-15T21:52:40.922271Z",
     "iopub.status.idle": "2024-05-15T22:02:51.581022Z",
     "shell.execute_reply": "2024-05-15T22:02:51.580040Z"
    },
    "papermill": {
     "duration": 610.669881,
     "end_time": "2024-05-15T22:02:51.583927",
     "exception": false,
     "start_time": "2024-05-15T21:52:40.914046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f931f5169b6846bcb1b165496ee303a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_PATH = \"/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# To prevent GPU memory overflow in Mixtral8x7b\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "config.gradient_checkpointing = True\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code = True,\n",
    "    quantization_config=quantization_config,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792bd135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T22:02:51.601683Z",
     "iopub.status.busy": "2024-05-15T22:02:51.601138Z",
     "iopub.status.idle": "2024-05-15T22:02:51.607312Z",
     "shell.execute_reply": "2024-05-15T22:02:51.606407Z"
    },
    "papermill": {
     "duration": 0.017349,
     "end_time": "2024-05-15T22:02:51.609500",
     "exception": false,
     "start_time": "2024-05-15T22:02:51.592151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_prompt(problem):\n",
    "    \n",
    "    return f\"\"\"\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\n",
    "### Instruction:\\n{problem}\\n\\n\n",
    "### Response: Let's think step by step. The final response should be a single number in the last line of your response.\n",
    "\"\"\"\n",
    "\n",
    "additional_prompt = \"So the answer is (final integer value):\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0bbe5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T22:02:51.625302Z",
     "iopub.status.busy": "2024-05-15T22:02:51.624998Z",
     "iopub.status.idle": "2024-05-15T22:02:51.629252Z",
     "shell.execute_reply": "2024-05-15T22:02:51.628364Z"
    },
    "papermill": {
     "duration": 0.014272,
     "end_time": "2024-05-15T22:02:51.631286",
     "exception": false,
     "start_time": "2024-05-15T22:02:51.617014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8b12369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T22:02:51.647290Z",
     "iopub.status.busy": "2024-05-15T22:02:51.646999Z",
     "iopub.status.idle": "2024-05-15T22:02:51.653090Z",
     "shell.execute_reply": "2024-05-15T22:02:51.651985Z"
    },
    "papermill": {
     "duration": 0.016631,
     "end_time": "2024-05-15T22:02:51.655403",
     "exception": false,
     "start_time": "2024-05-15T22:02:51.638772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to parse textual answer (integer at the end, possibly in a sentence\n",
    "pattern_answer = re.compile(r'(\\d+)(\\$|\\.|\\*)*$')\n",
    "def try_parse_answer(answer):\n",
    "    answer = answer.strip().split('\\n')[-1].strip().lower()\n",
    "    if match := re.search(pattern_answer, answer):\n",
    "        return int(match.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e071a2b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T22:02:51.671341Z",
     "iopub.status.busy": "2024-05-15T22:02:51.671053Z",
     "iopub.status.idle": "2024-05-15T22:04:44.723040Z",
     "shell.execute_reply": "2024-05-15T22:04:44.721839Z"
    },
    "papermill": {
     "duration": 113.064104,
     "end_time": "2024-05-15T22:04:44.726635",
     "exception": false,
     "start_time": "2024-05-15T22:02:51.662531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "2024-05-15 22:02:59.923079: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-15 22:02:59.923346: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-15 22:03:00.044039: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to help with that! The expression you've given is $1 - 1$. To evaluate this, we simply subtract 1 from 1. So:\n",
      "\n",
      "$1 - 1 = 0$\n",
      "\n",
      "Therefore, $1 - 1$ is equal to 0.\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to help you with that! The expression you've given is $0 \\times 10$.\n",
      "\n",
      "In numerical multiplication, when we multiply any number by 0, the result is always 0. This is a fundamental rule of arithmetic. Therefore, $0 \\times 10$ equals 0.\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to help you solve for $x$ in the equation $4 + x = 4$. Here's how we can solve it:\n",
      "\n",
      "1. The first step is to isolate $x$ on one side of the equation. To do this, we can subtract 4 from both sides of the equation. This gives us:\n",
      "\n",
      "$4 - 4 + x = 4 - 4$\n",
      "\n",
      "2. Simplifying both sides of the equation, we get:\n",
      "\n",
      "$0 + x = 0$\n",
      "\n",
      "3. Finally, we can simplify this equation to:\n",
      "\n",
      "$x = 0$\n",
      "\n",
      "Therefore, the solution to the equation $4 + x = 4$ is $x = 0$.\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "successes = 0\n",
    "total = 0\n",
    "\n",
    "for test, sample_submission in env.iter_test():\n",
    "    try:\n",
    "        problem = test['problem']\n",
    "        if not PRIVATE:\n",
    "            real_ans = test['answer']\n",
    "        query_prompt = gen_prompt(problem)\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            encoded_output = model.generate(inputs, \n",
    "                                            max_length=4096, \n",
    "                                            do_sample=True, \n",
    "                                            temperature=0.9,\n",
    "                                            top_p=0.95)\n",
    "        decoded_output = tokenizer.decode(encoded_output[0, inputs.shape[1]:], skip_special_tokens=True)\n",
    "        print(decoded_output)\n",
    "        answer = try_parse_answer(decoded_output)\n",
    "        \n",
    "        if answer is None:\n",
    "            print(additional_prompt)\n",
    "            messages.extend([\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": decoded_output\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": additional_prompt\n",
    "                }\n",
    "            ])\n",
    "            inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
    "            with torch.no_grad():\n",
    "                encoded_output = model.generate(inputs,\n",
    "                                                max_length=4096,\n",
    "                                                do_sample=True,\n",
    "                                                temperature=0.9,\n",
    "                                                top_p=0.95)\n",
    "\n",
    "            decoded_output = tokenizer.decode(encoded_output[0, inputs.shape[1]:], skip_special_tokens=True)\n",
    "            print(decoded_output)\n",
    "            answer = try_parse_answer(decoded_output)\n",
    "        \n",
    "        print(answer)\n",
    "        if answer is not None:\n",
    "            answer = int(round(answer)) % 1000\n",
    "            print(answer)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        answer = 0\n",
    "    sample_submission[\"answer\"] = answer\n",
    "    env.predict(sample_submission)\n",
    "    if not PRIVATE:\n",
    "        if answer == real_ans:\n",
    "            print(\"Success!\")\n",
    "            successes += 1\n",
    "        else:\n",
    "            print(f\"Failure! Real answer={real_ans}\")\n",
    "        total += 1\n",
    "        \n",
    "if not PRIVATE:\n",
    "    print(f\"Accuracy: {successes/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a0dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T18:41:18.476908Z",
     "iopub.status.busy": "2024-04-01T18:41:18.476279Z",
     "iopub.status.idle": "2024-04-01T18:41:18.500864Z",
     "shell.execute_reply": "2024-04-01T18:41:18.49998Z",
     "shell.execute_reply.started": "2024-04-01T18:41:18.476876Z"
    },
    "papermill": {
     "duration": 0.008734,
     "end_time": "2024-05-15T22:04:44.745106",
     "exception": false,
     "start_time": "2024-05-15T22:04:44.736372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b73ef",
   "metadata": {
    "papermill": {
     "duration": 0.008914,
     "end_time": "2024-05-15T22:04:44.762936",
     "exception": false,
     "start_time": "2024-05-15T22:04:44.754022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8365361,
     "sourceId": 73231,
     "sourceType": "competition"
    },
    {
     "datasetId": 4281572,
     "sourceId": 7369493,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 4761,
     "sourceId": 5994,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8318,
     "sourceId": 11382,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8332,
     "sourceId": 11394,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 776.565725,
   "end_time": "2024-05-15T22:04:48.607661",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-15T21:51:52.041936",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1c161d3c8afe44da8e17074bf610fee7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "360b277a67554094ad33646a7c79f798": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b921ef436eb243358b17d9196347f804",
       "placeholder": "​",
       "style": "IPY_MODEL_f247a42fda3d4a6aa215794588eed6cb",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "4f756a07c7ef40598e1d8518eee23370": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "632e020b3934419cb7cf6384ff91e602": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d1858bbc48aa4c33a7f1500d83996700",
       "max": 19.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_78dbee24cd224672a399e71ee4a8df83",
       "value": 19.0
      }
     },
     "77cf884defe04a9994cb04ac0900af15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78dbee24cd224672a399e71ee4a8df83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b921ef436eb243358b17d9196347f804": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c9731dacc55c4373925b1d482641cac3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4f756a07c7ef40598e1d8518eee23370",
       "placeholder": "​",
       "style": "IPY_MODEL_1c161d3c8afe44da8e17074bf610fee7",
       "value": " 19/19 [10:01&lt;00:00, 31.00s/it]"
      }
     },
     "d1858bbc48aa4c33a7f1500d83996700": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f247a42fda3d4a6aa215794588eed6cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f931f5169b6846bcb1b165496ee303a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_360b277a67554094ad33646a7c79f798",
        "IPY_MODEL_632e020b3934419cb7cf6384ff91e602",
        "IPY_MODEL_c9731dacc55c4373925b1d482641cac3"
       ],
       "layout": "IPY_MODEL_77cf884defe04a9994cb04ac0900af15"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
